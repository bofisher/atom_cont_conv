
# Atom Echo – Continued-Conversation Satellite

> **⚠️ IMPORTANT UPDATE - ESPHome 2025.9**
> 
> **The custom voice_assistant component in this repository IS REQUIRED for external audio setups!**
> 
> While ESPHome has improved significantly, the voice_assistant component still has critical issues when using external audio systems (like Sonos speakers) instead of ESP32 onboard speakers. The `esphome/custom_components/voice_assistant/` folder contains essential fixes for:
> 
> - **State machine completion** - Prevents getting stuck in "Responding" state
> - **External audio coordination** - Proper state transitions with Sonos/external speakers
> - **Continue conversation functionality** - Enables multi-turn conversations
> - **Ask question support** - Allows HA to programmatically start voice interactions
> 
> **For external audio setups:** Use the custom voice_assistant component from this repository.
> 
> **For onboard ESP speaker setups:** The standard ESPHome component may work, but this version is recommended for reliability.

---

> **Disclaimer**
> README generated by LLM  
> This firmware is a **proof of concept** and will not be a one‑click flash for most users.  
> You’ll need intermediate ESPHome & Home Assistant skills to:
> * Compile/flash your tweaked version of `atom_echo_firmware.yaml` to your Atom Echo  
> * Import and adjust `play_tts_message_v2.yaml` in Home Assistant  
> * Provide a “ding” / acknowledgement sound (host it yourself, reference its URL)  
> * Point the script at your own media‑player entities  
> * Fine‑tune any other substitutions (Wi‑Fi, encryption key, OTA password, etc.)

---

## Repository Contents

| File | Purpose |
|------|---------|
| **`atom_echo_firmware.yaml`** | ESPHome config for Atom Echo with MicroWakeWord and continued-conversation logic |
| **`device_specific_firmware.yaml`** | Device-specific ESPHome config, includes the main firmware, sets min ESPHome version, WiFi, encryption, etc. |
| **`play_tts_message_v2.yaml`** | Home Assistant script that plays TTS/ack audio, toggles `input_boolean.tts_playing`, inserts delays based on transcript word count |
| **`mww_training_w_cuda_requirements.txt`** | Python requirements for MicroWakeWord model training (TensorFlow, PyTorch, etc.) |
| **`sensor.assist_devices_active_list`** | Example template helper that shows list of satellites currently in use. |
| **`esphome/custom_components/`** | **✅ REQUIRED for external audio** - Custom voice_assistant component with critical fixes for external audio setups (Sonos, etc.) |

---

## Required Home Assistant Entities

| Entity | Type | Purpose |
|--------|------|--------|
| `input_boolean.tts_playing` | Boolean | Indicates TTS playback is active; used to gate microphone |
| `input_text.tts_transcript` | Text | Stores last TTS message for delay calculation and transcript management |
| `sensor.assist_devices_active_list` | Text | Comma separated list of assist satellites currently in use. Template helper. |

---

## Feature Highlights

* **Continued Conversation** – Automatically keeps the mic open for follow‑up questions when the response ends with a question mark.  
* **Smart TTS gating** – The helper script turns **`tts_playing` on** before audio playback and **off** after a delay so the microphone ignores the speaker.  
* Single‑LED feedback: idle, listening, thinking, error, with multiple custom effects (Slow Pulse, Fast Pulse, Very Fast Pulse, etc.).
* **Device-specific config** – `device_specific_firmware.yaml` sets device name, WiFi, encryption, and requires ESPHome 2025.8.3+.
* **Transcript management** – Uses `input_text.tts_transcript` to store and clear the last TTS message.
* **MicroWakeWord model training** – See `mww_training_w_cuda_requirements.txt` for dependencies if you want to train your own wake word model.
* **Ask Question Automation** – Use Home Assistant’s `assist_satellite.ask_question` service to trigger a question, wait for a spoken response, and act on the answer.

---

## Workflow: Voice Assistant, TTS, and Ask Question

```mermaid
sequenceDiagram
    participant MW as micro_wake_word
    participant FW as firmware
    participant VA as voice_assistant
    participant HA as Home Assistant
    participant SCR as play_tts_message_v2
    participant User
    participant Automation
    Note over MW,FW: tts_playing = OFF
    MW->>FW: Wake word detected
    Note over FW: LED = blue (listening)
    FW->>SCR: Play *ding* on selected speaker (turn tts_playing ON)
    SCR->>SCR: delay 1.5s (fixed)
    SCR-->>FW: Ack finished (turn tts_playing OFF)
    FW->>MW: stop()
    FW->>VA: start()
    VA->>HA: Stream mic ➜ STT ➜ LLM
    HA-->>VA: TTS response
    VA->>FW: on_tts_start<br/>set transcript, check "?" ➜ set continue_convo
    Note over FW: LED = blue (thinking)
    VA->>SCR: Play TTS on speaker (turn tts_playing ON)
    SCR->>SCR: delay (computed from transcript word count, min 2s, max 30s)
    SCR->>HA: Clear transcript
    SCR-->>FW: TTS finished (turn tts_playing OFF)
    FW->>FW: wait until tts_playing == OFF
    FW->>VA: stop()
    alt continue_convo == true
        FW->>VA: start()  %% stays in conversation
    else continue_convo == false
        FW->>MW: start()  %% back to wake‑word idle
    end
    Note over FW: LED = green (idle)
    alt error
        FW->>FW: LED = red, log error
    end
    alt ask_question triggered
        Automation->>VA: assist_satellite.ask_question (e.g., "Should I turn on the light?")
        User->>VA: Answers yes/no
        VA->>Automation: Returns answer, automation acts accordingly
    end
```

---

## Key Decision Points

| Stage | Condition / Check | Action |
|-------|------------------|--------|
| **on_wake_word_detected** | `tts_playing` must be **OFF** | Prevents re‑trigger during playback |
| **on_tts_start** | Response text ends with “?” | Sets global `continue_convo` |
| **on_end** | Wait until `tts_playing` is **OFF** | Then either restart **voice_assistant** (follow‑up) or **micro_wake_word** (idle) |
| **ask_question** | Automation triggers question | Waits for user response, acts on answer |

---

## TTS Script Logic and Delay Calculation

The script `play_tts_message_media_player_v2` manages TTS playback and microphone gating:

1. Sets `tts_playing` ON before playback.
2. Plays TTS or ding sound on the selected media player.
3. Calculates delay based on transcript word count:
   - Counts words in `input_text.tts_transcript`.
   - Uses WPM (words per minute) to estimate duration:
     - `computed_delay = clamp(round(words / WPM * 60), min, max)`
     - WPM and clamp values are configurable (e.g., WPM=170, min=2s, max=30s).
   - For short responses, WPM may be increased for more accurate timing.
4. Clears transcript after playback.
5. Sets `tts_playing` OFF after the delay.

This ensures the Atom Echo does not react to its own TTS playback and resumes listening only when safe.

---

## Ask Question Automation: How It Works

- The `assist_satellite.ask_question` service lets automations/scripts send a question to a voice assistant device (satellite).
- The device asks the question (e.g., "Should I turn on the light?") and waits for the user’s spoken response.
- The automation parses the answer (yes/no or custom) and triggers actions based on the reply.
- This enables interactive, voice-driven automations (e.g., confirming actions, making choices).
- Example: After a command, the system can ask for confirmation before toggling a switch.

---

## Extending ask_question for Multi-Step Dialogs

You can chain multiple `assist_satellite.ask_question` calls in your automations to create more complex, multi-step voice dialogs. For example, after confirming an action, you can immediately ask a follow-up question and branch logic based on each response. This enables interactive, guided workflows for advanced use cases.

---

## References

* Home Assistant 2025.4 – [Continued Conversation with LLMs](https://www.home-assistant.io/blog/2025/04/02/release-20254/#continued-conversation-with-llms)  
* ESPHome MicroWakeWord component – <https://esphome.io/components/micro_wake_word.html>
* ESPHome minimum version required: **2025.9.0** (with custom voice_assistant component for external audio fixes)
* MicroWakeWord model training requirements: see `mww_training_w_cuda_requirements.txt`

---

## Version History

- **2025-09-14**: Updated for ESPHome 2025.9 - custom voice_assistant component REQUIRED for external audio setups (contains critical state machine and audio coordination fixes)
- **2025-09-10**: Updated for ESPHome 2025.8.3 - custom voice_assistant component no longer needed (INCORRECT - later discovered still needed for external audio)
- **2025-07-27**: Initial release with custom voice_assistant workarounds

---

*README updated 2025-09-14*
